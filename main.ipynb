{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79142251",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "from tqdm import tqdm\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c72d1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = YOLO(\"best.pt\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23c8b22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'ball', 1: 'goalkeeper', 2: 'player', 3: 'referee'}\n"
     ]
    }
   ],
   "source": [
    "# Confirm model class labels\n",
    "print(model.names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0a66b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = '15sec_input_720p.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Get video details\n",
    "width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps    = cap.get(cv2.CAP_PROP_FPS)\n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# Output writer setup\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('output_reid_3.mp4', fourcc, fps, (width, height))\n",
    "\n",
    "# Initialize DeepSort\n",
    "tracker = DeepSort(max_age=30, n_init=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39b42f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Processing frame: 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 ball, 16 players, 2 referees, 346.5ms\n",
      "Speed: 3.4ms preprocess, 346.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[INFO] Processing frame: 1\n",
      "\n",
      "0: 384x640 18 players, 2 referees, 258.5ms\n",
      "Speed: 0.9ms preprocess, 258.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[INFO] Processing frame: 2\n",
      "\n",
      "0: 384x640 1 ball, 16 players, 2 referees, 258.0ms\n",
      "Speed: 1.0ms preprocess, 258.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[INFO] Processing frame: 3\n",
      "\n",
      "0: 384x640 1 ball, 14 players, 2 referees, 266.2ms\n",
      "Speed: 0.8ms preprocess, 266.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[INFO] Processing frame: 4\n",
      "\n",
      "0: 384x640 1 ball, 14 players, 2 referees, 261.0ms\n",
      "Speed: 1.0ms preprocess, 261.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[INFO] Processing frame: 5\n",
      "\n",
      "0: 384x640 1 ball, 16 players, 2 referees, 252.3ms\n",
      "Speed: 1.0ms preprocess, 252.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[INFO] Processing frame: 6\n",
      "\n",
      "0: 384x640 15 players, 2 referees, 264.5ms\n",
      "Speed: 1.8ms preprocess, 264.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[INFO] Processing frame: 7\n",
      "\n",
      "0: 384x640 15 players, 1 referee, 248.9ms\n",
      "Speed: 0.9ms preprocess, 248.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[INFO] Processing frame: 8\n",
      "\n",
      "0: 384x640 1 ball, 15 players, 2 referees, 241.8ms\n",
      "Speed: 1.7ms preprocess, 241.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[INFO] Processing frame: 9\n",
      "\n",
      "0: 384x640 1 ball, 15 players, 2 referees, 268.0ms\n",
      "Speed: 0.9ms preprocess, 268.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[INFO] Processing frame: 10\n",
      "\n",
      "0: 384x640 1 ball, 16 players, 3 referees, 272.9ms\n",
      "Speed: 1.0ms preprocess, 272.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[INFO] Processing frame: 11\n",
      "\n",
      "0: 384x640 1 ball, 15 players, 3 referees, 261.7ms\n",
      "Speed: 0.9ms preprocess, 261.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[INFO] Processing frame: 12\n",
      "\n",
      "0: 384x640 1 ball, 13 players, 2 referees, 275.0ms\n",
      "Speed: 0.8ms preprocess, 275.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[INFO] Processing frame: 13\n",
      "\n",
      "0: 384x640 15 players, 2 referees, 254.5ms\n",
      "Speed: 0.8ms preprocess, 254.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[INFO] Processing frame: 14\n",
      "\n",
      "0: 384x640 14 players, 2 referees, 251.6ms\n",
      "Speed: 0.8ms preprocess, 251.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[INFO] Processing frame: 15\n",
      "\n",
      "0: 384x640 18 players, 2 referees, 275.4ms\n",
      "Speed: 1.8ms preprocess, 275.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[INFO] Processing frame: 16\n",
      "\n",
      "0: 384x640 14 players, 2 referees, 310.1ms\n",
      "Speed: 1.0ms preprocess, 310.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[INFO] Processing frame: 17\n",
      "\n",
      "0: 384x640 15 players, 2 referees, 268.6ms\n",
      "Speed: 0.8ms preprocess, 268.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[INFO] Processing frame: 18\n",
      "\n",
      "0: 384x640 15 players, 2 referees, 273.6ms\n",
      "Speed: 1.0ms preprocess, 273.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[INFO] Processing frame: 19\n",
      "\n",
      "0: 384x640 16 players, 2 referees, 246.2ms\n",
      "Speed: 1.0ms preprocess, 246.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[INFO] Processing frame: 20\n",
      "\n",
      "0: 384x640 14 players, 1 referee, 249.1ms\n",
      "Speed: 1.0ms preprocess, 249.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[INFO] Processing frame: 21\n",
      "\n",
      "0: 384x640 14 players, 4 referees, 246.4ms\n",
      "Speed: 0.8ms preprocess, 246.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[INFO] Processing frame: 22\n",
      "\n",
      "0: 384x640 14 players, 3 referees, 252.2ms\n",
      "Speed: 0.8ms preprocess, 252.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[INFO] Processing frame: 23\n",
      "\n",
      "0: 384x640 14 players, 3 referees, 251.2ms\n",
      "Speed: 0.9ms preprocess, 251.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[DONE] Output saved to: output_reid.mp4\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "frame_idx = 0\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    print(f\"[INFO] Processing frame: {frame_idx}\")\n",
    "    \n",
    "    # Run YOLOv8 inference\n",
    "    results = model(frame)[0]  # [0] to get first result\n",
    "\n",
    "    detections = []\n",
    "    for box in results.boxes:\n",
    "        cls = int(box.cls.item())\n",
    "        conf = float(box.conf.item())\n",
    "        \n",
    "        # Only player (class 2), confidence threshold 0.5+\n",
    "        if cls == 2 and conf > 0.5:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())\n",
    "            w, h = x2 - x1, y2 - y1\n",
    "\n",
    "            # Optional filter: ignore tiny detections (false positives)\n",
    "            if w < 20 or h < 40:\n",
    "                continue\n",
    "\n",
    "            detections.append(([x1, y1, w, h], conf, 'player'))\n",
    "\n",
    "\n",
    "    tracks = tracker.update_tracks(detections, frame=frame)\n",
    "\n",
    "    for track in tracks:\n",
    "        if not track.is_confirmed() or track.track_id is None:\n",
    "            continue\n",
    "\n",
    "        # Get track box\n",
    "        x1, y1, x2, y2 = map(int, track.to_ltrb())\n",
    "\n",
    "        # Filter out giant or tiny fake boxes\n",
    "        w, h = x2 - x1, y2 - y1\n",
    "        if w < 20 or h < 40 or w > 400 or h > 600:\n",
    "            continue\n",
    "\n",
    "        # Draw bounding box & ID label\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 255, 255), 2)\n",
    "        cv2.putText(frame, f'Player {track.track_id}', (x1, y1 - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "\n",
    "\n",
    "\n",
    "    # Write the output frame\n",
    "    out.write(frame)\n",
    "\n",
    "    # Optional: Show live preview (can comment out)\n",
    "    cv2.imshow(\"Tracking\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "    frame_idx += 1\n",
    "\n",
    "# Release everything\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"[DONE] Output saved to: output_reid.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35f8f83",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Confirm model class labels\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(model\u001b[38;5;241m.\u001b[39mnames)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef4ced9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
